{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# High-Level Overview of the Spiking Neural Network Simulation Script\n",
    "This script implements a biologically inspired spiking neural network (SNN) based on recent research. The network mimics certain aspects of how the human brain processes visual information and learns from experience. Below is a brief, non-technical summary of its main components and functionality:\n",
    "\n",
    "## 1. Input Processing (Retina Module)\n",
    "Purpose:\n",
    "Converts an input image (using MNIST as an example) into \"spike trains\"—a series of electrical pulses similar to signals sent by biological neurons.\n",
    "\n",
    "### How it Works:\n",
    "The image is processed via average pooling to reduce its resolution (mimicking the compression of visual data in the human retina). The resulting values are normalized and used to generate spike trains through a Poisson process.\n",
    "\n",
    "## 2. Middle (Liquid) Layer\n",
    "Purpose:\n",
    "Processes the spike trains from the retina in a network of neurons that resemble those in the brain.\n",
    "\n",
    "### Components:\n",
    "\n",
    "Excitatory Neurons: Send signals that stimulate other neurons.\n",
    "\n",
    "Inhibitory Neurons: Send signals that suppress activity.\n",
    "\n",
    "### How it Works:\n",
    "Neurons follow a Leaky Integrate-and-Fire (LIF) model. They accumulate incoming electrical signals over time and \"fire\" a spike when a threshold is reached, then reset to a resting state.\n",
    "\n",
    "## 3. Output Layer (Decision Making)\n",
    "### Purpose:\n",
    "Makes the final classification decision.\n",
    "\n",
    "### How it Works:\n",
    "Each neuron in the output layer corresponds to a class (for MNIST, digits 0-9). The decision is made based on which output neuron fires the most over the simulation period.\n",
    "\n",
    "## 4. Learning via Actor–Critic Module\n",
    "Purpose:\n",
    "Enables the network to learn and improve its performance over time.\n",
    "\n",
    "### Components:\n",
    "\n",
    "Spike-Timing Dependent Plasticity (STDP): Adjusts the strength of connections based on the timing of spikes.\n",
    "\n",
    "Actor–Critic Reinforcement Learning: Uses a \"critic\" to assess and provide feedback on the network's decisions, enabling reinforcement and fine-tuning of synaptic connections.\n",
    "\n",
    "### How it Works:\n",
    "The network adjusts its internal wiring (i.e., synaptic weights) using a combination of STDP and reward-based feedback (via the actor–critic method).\n",
    "\n",
    "## 5. GPU Acceleration with PyTorch\n",
    "### Purpose:\n",
    "To speed up computationally heavy tasks, particularly those involving large connectivity matrices.\n",
    "\n",
    "### How it Works:\n",
    "Key operations (like building and updating connectivity matrices) are performed using PyTorch. If a compatible GPU is available, these operations will run on the GPU, significantly reducing simulation time.\n",
    "\n",
    "## 6. Modularity and Tunability\n",
    "### Design Philosophy:\n",
    "The code is organized using clear, object-oriented modules:\n",
    "\n",
    "Each key component (Retina, Neuron, Layer, Actor–Critic, PSAC Network) is encapsulated in its own class.\n",
    "\n",
    "All important parameters (e.g., time constants, thresholds, learning rates, connectivity probabilities) are stored in a central configuration section (CONFIG), making it easy to adjust and experiment with the model."
   ],
   "id": "bc2b69c4451d0308"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %% [code]\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "A complete spiking neural network simulation and PSAC learning framework\n",
    "based on the paper “An accurate and fast learning approach in the biologically spiking neural network.”\n",
    "\n",
    "This version:\n",
    "  1. Loads the MNIST dataset from torchvision.\n",
    "  2. Utilizes PyTorch to offload some computations (connectivity matrices) to the GPU.\n",
    "  3. Maintains a modular, class-based code structure with clearly tunable parameters.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Check for GPU support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on device:\", device)\n",
    "\n",
    "# Global configuration dictionary: modify these to tune the simulation.\n",
    "CONFIG = {\n",
    "    \"simulation\": {\n",
    "        \"dt\": 1.0,             # time-step (ms)\n",
    "        \"t_total\": 1200,       # total simulation time in ms\n",
    "        \"t_skip\": 200,         # initial period skipped for stabilization (ms)\n",
    "    },\n",
    "    \"neuron\": {\n",
    "        \"tau_m_exc\": 20.0,     # membrane time constant for excitatory neurons (ms)\n",
    "        \"tau_m_inh\": 10.0,     # for inhibitory neurons (ms)\n",
    "        \"v_rest\": 0.0,         # resting potential (mV)\n",
    "        \"v_thresh\": 18.0,      # spike threshold (mV)\n",
    "        \"v_reset\": 0.0,        # reset potential after spike (mV)\n",
    "        \"refractory_exc\": 2.0, # refractory period (ms)\n",
    "        \"refractory_inh\": 1.0, # refractory period for inhibitory neurons (ms)\n",
    "    },\n",
    "    \"synapse\": {\n",
    "        \"tau_rA\": 1.0,         # excitatory synaptic rise time (ms)\n",
    "        \"tau_dA\": 20.0,        # excitatory synaptic decay time (ms)\n",
    "        \"tau_rG\": 1.0,         # inhibitory synaptic rise time (ms)\n",
    "        \"tau_dG\": 1.0,         # inhibitory synaptic decay time (ms)\n",
    "    },\n",
    "    \"network\": {\n",
    "        \"num_middle_neurons\": 5000,  # number of neurons in the middle (liquid) layer\n",
    "        \"ratio_exc\": 0.8,            # ratio of excitatory neurons in the middle layer\n",
    "        \"ratio_inh\": 0.2,            # ratio of inhibitory neurons in the middle layer\n",
    "        \"connection_prob\": 0.2,      # connection probability (sparse connectivity)\n",
    "        \"max_distance\": None,        # computed based on spatial layout; see below.\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"num_classes\": 10,      # number of output neurons (for MNIST, 10 classes)\n",
    "        \"simulation_window\": 1000,  # ms over which output neurons’ firing rates are measured\n",
    "    },\n",
    "    \"actor_critic\": {\n",
    "        \"num_critic_neurons\": 20,\n",
    "        \"gamma\": 0.99,         # discount factor for future rewards\n",
    "        \"tau_r\": 20.0,         # time constant scaling factor for the critic (ms)\n",
    "    },\n",
    "    \"learning\": {\n",
    "        \"learning_rate\": 0.001,  # base learning rate for weight updates (STDP modulation)\n",
    "        \"stdp_window\": 20.0,     # window (ms) for STDP temporal difference\n",
    "    },\n",
    "    \"retina\": {\n",
    "        \"input_size\": (28, 28),  # input image size (MNIST)\n",
    "        \"pool_size\": 2,          # pooling window size (e.g. 2x2)\n",
    "        \"stride\": 2,             # stride for pooling\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------- Neuron, Synapse, and Layer Classes --------------------\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, neuron_id, is_excitatory=True, config=CONFIG):\n",
    "        self.id = neuron_id\n",
    "        self.is_excitatory = is_excitatory\n",
    "        self.config = config\n",
    "        if self.is_excitatory:\n",
    "            self.tau_m = config[\"neuron\"][\"tau_m_exc\"]\n",
    "            self.refractory_period = config[\"neuron\"][\"refractory_exc\"]\n",
    "        else:\n",
    "            self.tau_m = config[\"neuron\"][\"tau_m_inh\"]\n",
    "            self.refractory_period = config[\"neuron\"][\"refractory_inh\"]\n",
    "        self.v = config[\"neuron\"][\"v_rest\"]\n",
    "        self.v_thresh = config[\"neuron\"][\"v_thresh\"]\n",
    "        self.v_reset = config[\"neuron\"][\"v_reset\"]\n",
    "        self.last_spike_time = -np.inf  # tracks last spike time (ms)\n",
    "        self.spike_times = []           # records all spike times\n",
    "\n",
    "    def update(self, t, dt, input_current):\n",
    "        # Check for refractory period\n",
    "        if (t - self.last_spike_time) < self.refractory_period:\n",
    "            self.v = self.v_reset\n",
    "            return False\n",
    "\n",
    "        # Euler integration for LIF dynamics\n",
    "        dv = (-self.v + input_current) * dt / self.tau_m\n",
    "        self.v += dv\n",
    "\n",
    "        # Spike if threshold is crossed\n",
    "        if self.v >= self.v_thresh:\n",
    "            self.spike(t)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def spike(self, t):\n",
    "        self.spike_times.append(t)\n",
    "        self.last_spike_time = t\n",
    "        self.v = self.v_reset  # reset membrane potential\n",
    "\n",
    "# A minimal Synapse blueprint is provided. In this implementation, synaptic dynamics are managed via connectivity matrices.\n",
    "class Synapse:\n",
    "    def __init__(self, pre_neuron, post_neuron, weight, delay=1.0, is_excitatory=True, config=CONFIG):\n",
    "        self.pre = pre_neuron\n",
    "        self.post = post_neuron\n",
    "        self.weight = weight\n",
    "        self.delay = delay  # synaptic delay (ms)\n",
    "        self.is_excitatory = is_excitatory\n",
    "        self.config = config\n",
    "        self.x = 0.0  # auxiliary variable for synaptic rise dynamics\n",
    "        self.I = 0.0  # synaptic current variable\n",
    "        self.tau_r = config[\"synapse\"][\"tau_rA\"] if is_excitatory else config[\"synapse\"][\"tau_rG\"]\n",
    "        self.tau_d = config[\"synapse\"][\"tau_dA\"] if is_excitatory else config[\"synapse\"][\"tau_dG\"]\n",
    "\n",
    "    def update(self, dt):\n",
    "        # Euler integration for synaptic dynamics (simplified)\n",
    "        dx = -self.x * dt / self.tau_r\n",
    "        self.x += dx\n",
    "        dI = (-self.I + self.x) * dt / self.tau_d\n",
    "        self.I += dI\n",
    "\n",
    "    def transmit_spike(self):\n",
    "        # When a spike is transmitted, update the auxiliary variable\n",
    "        self.x += self.weight  # additional scaling can be added as needed\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, size, is_excitatory_array, config=CONFIG, name=\"layer\"):\n",
    "        self.config = config\n",
    "        self.name = name\n",
    "        self.neurons = []\n",
    "        for i in range(size):\n",
    "            neuron = Neuron(i, is_excitatory=is_excitatory_array[i], config=config)\n",
    "            self.neurons.append(neuron)\n",
    "        self.size = size\n",
    "\n",
    "    def update(self, t, dt, input_currents):\n",
    "        \"\"\"Update every neuron in the layer with its corresponding input current.\n",
    "           Returns a list of indices for neurons that spiked at time t.\"\"\"\n",
    "        spikes = []\n",
    "        for i, neuron in enumerate(self.neurons):\n",
    "            if neuron.update(t, dt, input_currents[i]):\n",
    "                spikes.append(i)\n",
    "        return spikes\n",
    "\n",
    "\n",
    "# -------------------- Retina Module --------------------\n",
    "\n",
    "class Retina:\n",
    "    def __init__(self, config=CONFIG):\n",
    "        self.config = config\n",
    "        self.input_size = config[\"retina\"][\"input_size\"]\n",
    "        self.pool_size = config[\"retina\"][\"pool_size\"]\n",
    "        self.stride = config[\"retina\"][\"stride\"]\n",
    "        # Determine output dimensions after pooling\n",
    "        self.output_dim = (\n",
    "            self.input_size[0] // self.stride,\n",
    "            self.input_size[1] // self.stride\n",
    "        )\n",
    "\n",
    "    def process_image(self, image):\n",
    "        \"\"\"\n",
    "        Process the image through average pooling to reduce dimensionality.\n",
    "        The resulting array represents activation levels.\n",
    "        \"\"\"\n",
    "        pooled = self.pool(image, self.pool_size, self.stride)\n",
    "        # Normalize pooled image (assuming pixel values 0-255)\n",
    "        spike_rates = pooled / 255.0  # yields a value between 0 and 1\n",
    "        return spike_rates\n",
    "\n",
    "    def pool(self, image, pool_size, stride):\n",
    "        out_h = image.shape[0] // stride\n",
    "        out_w = image.shape[1] // stride\n",
    "        pooled = np.zeros((out_h, out_w))\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                window = image[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]\n",
    "                pooled[i, j] = np.mean(window)\n",
    "        return pooled\n",
    "\n",
    "    def generate_spike_trains(self, spike_rates, simulation_time, dt):\n",
    "        \"\"\"\n",
    "        For each pooled unit, generate a spike train based on a Poisson process.\n",
    "        Returns a dictionary: key: neuron index, value: list of spike times.\n",
    "        \"\"\"\n",
    "        num_neurons = spike_rates.shape[0] * spike_rates.shape[1]\n",
    "        spike_trains = {i: [] for i in range(num_neurons)}\n",
    "        num_steps = int(simulation_time / dt)\n",
    "        for step in range(num_steps):\n",
    "            t = step * dt\n",
    "            for i in range(spike_rates.shape[0]):\n",
    "                for j in range(spike_rates.shape[1]):\n",
    "                    idx = i * spike_rates.shape[1] + j\n",
    "                    # Using the spike_rate (interpreted as Hz) to decide spike emission\n",
    "                    if np.random.rand() < spike_rates[i, j] * dt / 1000.0:\n",
    "                        spike_trains[idx].append(t)\n",
    "        return spike_trains\n",
    "\n",
    "\n",
    "# -------------------- Actor-Critic Module --------------------\n",
    "\n",
    "class ActorCritic:\n",
    "    def __init__(self, config=CONFIG):\n",
    "        self.config = config\n",
    "        self.num_neurons = config[\"actor_critic\"][\"num_critic_neurons\"]\n",
    "        # Create a critic layer (all excitatory for simplicity)\n",
    "        self.critic_layer = Layer(self.num_neurons, [True]*self.num_neurons, config=config, name=\"Critic\")\n",
    "        self.last_value = 0.0\n",
    "\n",
    "    def compute_value(self):\n",
    "        \"\"\"Estimate the state value as the average firing rate of the critic neurons.\"\"\"\n",
    "        rates = [len(neuron.spike_times) for neuron in self.critic_layer.neurons]\n",
    "        value = np.mean(rates)\n",
    "        return value\n",
    "\n",
    "    def update(self, reward, gamma):\n",
    "        \"\"\"\n",
    "        Compute the reward prediction error (delta) and update state.\n",
    "        delta = r_{t+1} + gamma * V(s_{t+1}) - V(s_t)\n",
    "        \"\"\"\n",
    "        current_value = self.compute_value()\n",
    "        delta = reward + gamma * current_value - self.last_value\n",
    "        self.last_value = current_value\n",
    "        return delta\n",
    "\n",
    "    def simulate(self, t, dt):\n",
    "        \"\"\"Update the critic neurons (with a dummy input current of 0).\"\"\"\n",
    "        input_currents = [0.0] * self.num_neurons\n",
    "        _ = self.critic_layer.update(t, dt, input_currents)\n",
    "\n",
    "\n",
    "# -------------------- PSAC Network (Main) --------------------\n",
    "\n",
    "class PSACNetwork:\n",
    "    def __init__(self, config=CONFIG):\n",
    "        self.config = config\n",
    "        self.dt = config[\"simulation\"][\"dt\"]\n",
    "\n",
    "        # Build the retina module\n",
    "        self.retina = Retina(config=config)\n",
    "        self.input_dim = self.retina.output_dim\n",
    "        self.num_input_neurons = self.input_dim[0] * self.input_dim[1]\n",
    "\n",
    "        # Build the middle layer (liquid layer)\n",
    "        num_middle = config[\"network\"][\"num_middle_neurons\"]\n",
    "        num_exc = int(num_middle * config[\"network\"][\"ratio_exc\"])\n",
    "        num_inh = num_middle - num_exc\n",
    "        exc_flags = [True] * num_exc + [False] * num_inh\n",
    "        np.random.shuffle(exc_flags)  # randomize neuron types\n",
    "        self.middle_layer = Layer(num_middle, exc_flags, config=config, name=\"Middle\")\n",
    "\n",
    "        # Build the output layer (all excitatory for classification)\n",
    "        num_classes = config[\"output\"][\"num_classes\"]\n",
    "        self.output_layer = Layer(num_classes, [True] * num_classes, config=config, name=\"Output\")\n",
    "\n",
    "        # Build the Actor-Critic module.\n",
    "        self.actor_critic = ActorCritic(config=config)\n",
    "\n",
    "        # Set up connectivity matrices between layers:\n",
    "        # (1) From middle to output: create full connectivity with a probability mask.\n",
    "        self.middle_to_output = self.create_connectivity(len(self.middle_layer.neurons),\n",
    "                                                         len(self.output_layer.neurons), config)\n",
    "        # (2) In the middle layer, use distance-based (exponential decay) connectivity.\n",
    "        self.middle_layer_positions = self.initialize_positions(num_middle)\n",
    "        self.config[\"network\"][\"max_distance\"] = np.sqrt(\n",
    "            (np.max(self.middle_layer_positions[:, 0]) - np.min(self.middle_layer_positions[:, 0])) ** 2 +\n",
    "            (np.max(self.middle_layer_positions[:, 1]) - np.min(self.middle_layer_positions[:, 1])) ** 2\n",
    "        )\n",
    "        self.middle_layer_connectivity = self.create_spatial_connectivity(num_middle, config)\n",
    "\n",
    "    def initialize_positions(self, num_neurons):\n",
    "        \"\"\"Assign each neuron a random 2D position for distance-dependent connectivity.\"\"\"\n",
    "        positions = np.random.rand(num_neurons, 2) * 100.0  # positions in the range [0, 100)\n",
    "        return positions\n",
    "\n",
    "    def create_connectivity(self, pre_size, post_size, config):\n",
    "        connection_prob = config[\"network\"][\"connection_prob\"]\n",
    "        # Create connectivity matrix using PyTorch on the GPU if available.\n",
    "        connectivity = (torch.rand(pre_size, post_size, device=device) < connection_prob).float()\n",
    "        weights = torch.normal(mean=0.5, std=0.1, size=(pre_size, post_size), device=device)\n",
    "        weights *= connectivity  # apply mask so only some connections exist\n",
    "        return weights  # stays on the GPU\n",
    "\n",
    "    def create_spatial_connectivity(self, num_neurons, config):\n",
    "        connection_prob = config[\"network\"][\"connection_prob\"]\n",
    "        positions = self.middle_layer_positions\n",
    "        connectivity = np.zeros((num_neurons, num_neurons))\n",
    "        for i in range(num_neurons):\n",
    "            for j in range(num_neurons):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if np.random.rand() < connection_prob:\n",
    "                    r = np.linalg.norm(positions[i] - positions[j])\n",
    "                    D = config[\"network\"][\"max_distance\"]\n",
    "                    weight = np.exp(-r / D)\n",
    "                    connectivity[i, j] = weight\n",
    "        # Convert spatial connectivity to a torch tensor on the GPU.\n",
    "        return torch.tensor(connectivity, dtype=torch.float32, device=device)\n",
    "\n",
    "    def run_simulation(self, input_image, reward, verbose=False):\n",
    "        \"\"\"\n",
    "        Run one simulation episode for a single image.\n",
    "        Simulate the network dynamics over time, apply STDP/actor-critic updates,\n",
    "        and return the predicted class (based on highest output spike count).\n",
    "        \"\"\"\n",
    "        # Process the input image through the retina.\n",
    "        spike_rates = self.retina.process_image(input_image)\n",
    "        input_spike_trains = self.retina.generate_spike_trains(spike_rates, self.config[\"simulation\"][\"t_total\"], self.dt)\n",
    "\n",
    "        t_total = self.config[\"simulation\"][\"t_total\"]\n",
    "        dt = self.dt\n",
    "        num_steps = int(t_total / dt)\n",
    "        output_spike_counts = np.zeros(len(self.output_layer.neurons))\n",
    "\n",
    "        # Main simulation loop.\n",
    "        for step in range(num_steps):\n",
    "            t = step * dt\n",
    "\n",
    "            # --- Input layer processing ---\n",
    "            input_currents = np.zeros(self.num_input_neurons)\n",
    "            for neuron_idx, spike_times in input_spike_trains.items():\n",
    "                if t in spike_times:\n",
    "                    input_currents[neuron_idx] = 10.0  # tunable scale factor\n",
    "\n",
    "            # Map input layer to middle layer: using a simple uniform projection.\n",
    "            middle_input = np.zeros(len(self.middle_layer.neurons))\n",
    "            middle_input += np.sum(input_currents) * 0.01\n",
    "\n",
    "            # --- Middle layer update ---\n",
    "            middle_spikes = self.middle_layer.update(t, dt, middle_input)\n",
    "\n",
    "            # Propagate recurrent input within the middle layer using spatial connectivity.\n",
    "            recurrent_input = np.zeros(len(self.middle_layer.neurons))\n",
    "            for neuron_idx in middle_spikes:\n",
    "                # Convert the corresponding row from GPU (torch) to numpy.\n",
    "                recurrent_input += self.middle_layer_connectivity[neuron_idx, :].cpu().numpy()\n",
    "\n",
    "            # --- Projection to Output layer ---\n",
    "            output_input = np.zeros(len(self.output_layer.neurons))\n",
    "            for i in middle_spikes:\n",
    "                # Accumulate contributions from the middle-to-output connections.\n",
    "                output_input += self.middle_to_output[i, :].cpu().numpy() * 10.0  # tunable factor\n",
    "            output_spikes = self.output_layer.update(t, dt, output_input)\n",
    "\n",
    "            # Record output spikes after stabilization period.\n",
    "            if t >= self.config[\"simulation\"][\"t_skip\"]:\n",
    "                for idx in output_spikes:\n",
    "                    output_spike_counts[idx] += 1\n",
    "\n",
    "            # --- Actor-Critic update ---\n",
    "            self.actor_critic.simulate(t, dt)\n",
    "            # A placeholder STDP update: if middle and output neurons spiked, adjust weights modulated by RPE.\n",
    "            if middle_spikes and output_spikes:\n",
    "                delta = self.actor_critic.update(reward, self.config[\"actor_critic\"][\"gamma\"])\n",
    "                for m in middle_spikes:\n",
    "                    for o in output_spikes:\n",
    "                        # Update weight on the GPU, then clamp between 0 and 1.\n",
    "                        self.middle_to_output[m, o] += self.config[\"learning\"][\"learning_rate\"] * delta\n",
    "                        self.middle_to_output[m, o] = torch.clamp(self.middle_to_output[m, o], 0, 1.0)\n",
    "\n",
    "            if verbose and step % 100 == 0:\n",
    "                print(f\"Time {t:.1f} ms: Middle spikes: {len(middle_spikes)}, Output spikes: {len(output_spikes)}\")\n",
    "\n",
    "        # Determine the decision by taking the output neuron with the highest spike count.\n",
    "        predicted_class = int(np.argmax(output_spike_counts))\n",
    "        return predicted_class, output_spike_counts\n",
    "\n",
    "\n",
    "# -------------------- Main Routine (Using MNIST) --------------------\n",
    "\n",
    "# Import torchvision to load MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transform to convert image to tensor and scale it to [0, 255]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x * 255)\n",
    "])\n",
    "\n",
    "# Download and load the MNIST test dataset\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "sample_image_tensor, label = mnist_dataset[0]\n",
    "dummy_image = sample_image_tensor.squeeze().numpy()  # Convert to (28,28) numpy array\n",
    "\n",
    "print(\"True label of the selected MNIST sample:\", label)\n",
    "\n",
    "# Define a dummy reward (for example, 1.0 if correct classification)\n",
    "reward = 1.0\n",
    "\n",
    "# Instantiate the PSACNetwork\n",
    "network = PSACNetwork(CONFIG)\n",
    "predicted_class, output_counts = network.run_simulation(dummy_image, reward, verbose=True)\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Output spike counts:\", output_counts)\n",
    "\n",
    "# Optionally, visualize the output spike counts\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(len(output_counts)), output_counts)\n",
    "plt.xlabel(\"Output Neuron (Class)\")\n",
    "plt.ylabel(\"Spike Count\")\n",
    "plt.title(\"Output Layer Spike Counts After Simulation\")\n",
    "plt.show()\n"
   ],
   "id": "7cd116039af94a55"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
