{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# High-Level Overview of the Spiking Neural Network Simulation Script\n",
    "This script implements a biologically inspired spiking neural network (SNN) based on recent research. The network mimics certain aspects of how the human brain processes visual information and learns from experience. Below is a brief, non-technical summary of its main components and functionality:\n",
    "\n",
    "## 1. Input Processing (Retina Module)\n",
    "Purpose:\n",
    "Converts an input image (using MNIST as an example) into \"spike trains\"—a series of electrical pulses similar to signals sent by biological neurons.\n",
    "\n",
    "### How it Works:\n",
    "The image is processed via average pooling to reduce its resolution (mimicking the compression of visual data in the human retina). The resulting values are normalized and used to generate spike trains through a Poisson process.\n",
    "\n",
    "## 2. Middle (Liquid) Layer\n",
    "Purpose:\n",
    "Processes the spike trains from the retina in a network of neurons that resemble those in the brain.\n",
    "\n",
    "### Components:\n",
    "\n",
    "Excitatory Neurons: Send signals that stimulate other neurons.\n",
    "\n",
    "Inhibitory Neurons: Send signals that suppress activity.\n",
    "\n",
    "### How it Works:\n",
    "Neurons follow a Leaky Integrate-and-Fire (LIF) model. They accumulate incoming electrical signals over time and \"fire\" a spike when a threshold is reached, then reset to a resting state.\n",
    "\n",
    "## 3. Output Layer (Decision Making)\n",
    "### Purpose:\n",
    "Makes the final classification decision.\n",
    "\n",
    "### How it Works:\n",
    "Each neuron in the output layer corresponds to a class (for MNIST, digits 0-9). The decision is made based on which output neuron fires the most over the simulation period.\n",
    "\n",
    "## 4. Learning via Actor–Critic Module\n",
    "Purpose:\n",
    "Enables the network to learn and improve its performance over time.\n",
    "\n",
    "### Components:\n",
    "\n",
    "Spike-Timing Dependent Plasticity (STDP): Adjusts the strength of connections based on the timing of spikes.\n",
    "\n",
    "Actor–Critic Reinforcement Learning: Uses a \"critic\" to assess and provide feedback on the network's decisions, enabling reinforcement and fine-tuning of synaptic connections.\n",
    "\n",
    "### How it Works:\n",
    "The network adjusts its internal wiring (i.e., synaptic weights) using a combination of STDP and reward-based feedback (via the actor–critic method).\n",
    "\n",
    "## 5. GPU Acceleration with PyTorch\n",
    "### Purpose:\n",
    "To speed up computationally heavy tasks, particularly those involving large connectivity matrices.\n",
    "\n",
    "### How it Works:\n",
    "Key operations (like building and updating connectivity matrices) are performed using PyTorch. If a compatible GPU is available, these operations will run on the GPU, significantly reducing simulation time.\n",
    "\n",
    "## 6. Modularity and Tunability\n",
    "### Design Philosophy:\n",
    "The code is organized using clear, object-oriented modules:\n",
    "\n",
    "Each key component (Retina, Neuron, Layer, Actor–Critic, PSAC Network) is encapsulated in its own class.\n",
    "\n",
    "All important parameters (e.g., time constants, thresholds, learning rates, connectivity probabilities) are stored in a central configuration section (CONFIG), making it easy to adjust and experiment with the model."
   ],
   "id": "bc2b69c4451d0308"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %% [code]\n",
    "\"\"\"\n",
    "Extended GPU-accelerated Spiking Neural Network Training with PSAC for MNIST\n",
    "Adapted for use in a Jupyter Notebook.\n",
    "This cell defines all classes and functions and then runs the training and testing loops.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set the device to CUDA if available (use \"mps\" for Apple M2 if needed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# -------------------- Configuration --------------------\n",
    "CONFIG = {\n",
    "    \"simulation\": {\n",
    "        \"dt\": 1.0,             # time-step (ms)\n",
    "        \"t_total\": 1200,       # total simulation time per episode (ms)\n",
    "        \"t_skip\": 200,         # initial period for stabilization (ms)\n",
    "    },\n",
    "    \"neuron\": {\n",
    "        \"v_rest\": 0.0,         # resting potential (mV)\n",
    "        \"v_thresh\": 18.0,      # spike threshold (mV)\n",
    "        \"v_reset\": 0.0,        # reset potential (mV)\n",
    "    },\n",
    "    \"middle_layer\": {\n",
    "        \"num_neurons\": 5000,\n",
    "        \"ratio_exc\": 0.8,      # 80% excitatory neurons, 20% inhibitory\n",
    "        \"tau_m_exc\": 20.0,     # membrane time constant for excitatory neurons (ms)\n",
    "        \"tau_m_inh\": 10.0,     # membrane time constant for inhibitory neurons (ms)\n",
    "        \"refractory_exc\": 2.0, # refractory period (ms) for excitatory neurons\n",
    "        \"refractory_inh\": 1.0, # refractory period (ms) for inhibitory neurons\n",
    "    },\n",
    "    \"output_layer\": {\n",
    "        \"num_neurons\": 10,     # MNIST: 10 classes\n",
    "        \"tau_m\": 20.0,         # membrane time constant for output neurons (ms)\n",
    "        \"refractory\": 2.0,     # refractory period for output neurons (ms)\n",
    "    },\n",
    "    \"network\": {\n",
    "        \"connection_prob\": 0.2,   # probability for random connectivity from middle to output\n",
    "    },\n",
    "    \"actor_critic\": {\n",
    "        \"num_critic_neurons\": 20,\n",
    "        \"gamma\": 0.99,            # discount factor for future rewards\n",
    "        \"tau_r\": 20.0,            # time constant for critic neurons (ms)\n",
    "    },\n",
    "    \"learning\": {\n",
    "        \"learning_rate\": 0.001,   # learning rate for weight updates\n",
    "    },\n",
    "    \"retina\": {\n",
    "        \"input_size\": (28, 28),   # MNIST images are 28x28\n",
    "        \"pool_size\": 2,           # average pooling window size (2x2)\n",
    "        \"stride\": 2,              # stride for pooling (results in 7x7 output)\n",
    "        \"spike_rate_scaling\": 50.0  # multiplier to boost retina spike probability\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"num_epochs\": 2,          # Number of training epochs (set low for a prototype)\n",
    "        \"batch_size\": 1,          # We'll process one image per episode for simplicity\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------- Retina Module --------------------\n",
    "class Retina:\n",
    "    def __init__(self, config=CONFIG):\n",
    "        self.config = config\n",
    "        self.input_size = config[\"retina\"][\"input_size\"]\n",
    "        self.pool_size = config[\"retina\"][\"pool_size\"]\n",
    "        self.stride = config[\"retina\"][\"stride\"]\n",
    "        self.output_dim = (self.input_size[0] // self.stride,\n",
    "                           self.input_size[1] // self.stride)\n",
    "\n",
    "    def process_image(self, image):\n",
    "        \"\"\"\n",
    "        Downsample the input image using average pooling.\n",
    "        Returns a 2D array of activations (normalized between 0 and 1).\n",
    "        \"\"\"\n",
    "        h, w = self.input_size\n",
    "        pool_h, pool_w = self.pool_size, self.pool_size\n",
    "        out_h, out_w = self.output_dim\n",
    "        pooled = np.zeros((out_h, out_w))\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                window = image[i*self.stride : i*self.stride+pool_h,\n",
    "                               j*self.stride : j*self.stride+pool_w]\n",
    "                pooled[i, j] = np.mean(window)\n",
    "        spike_rates = pooled / 255.0\n",
    "        return spike_rates\n",
    "\n",
    "    def generate_spike_train(self, spike_rates, simulation_time, dt):\n",
    "        \"\"\"\n",
    "        Generate spike trains using a Poisson process.\n",
    "        Returns a torch tensor of shape [num_units, num_time_steps] on device.\n",
    "        \"\"\"\n",
    "        num_units = spike_rates.size\n",
    "        num_steps = int(simulation_time / dt)\n",
    "        spike_train = np.zeros((num_units, num_steps), dtype=np.float32)\n",
    "        scaling = self.config[\"retina\"].get(\"spike_rate_scaling\", 1.0)\n",
    "        for unit in range(num_units):\n",
    "            rate = spike_rates.flatten()[unit]  # normalized [0, 1]\n",
    "            probs = np.random.rand(num_steps)\n",
    "            spikes = (probs < (rate * scaling * dt / 1000.0)).astype(np.float32)\n",
    "            spike_train[unit] = spikes\n",
    "        return torch.tensor(spike_train, device=device, dtype=torch.float32)\n",
    "\n",
    "# -------------------- GPU-Accelerated Layer Class --------------------\n",
    "class LayerGPU:\n",
    "    def __init__(self, num_neurons, tau_m, v_rest, v_thresh, v_reset, refractory, device):\n",
    "        \"\"\"\n",
    "        Vectorized layer of LIF neurons.\n",
    "        tau_m and refractory are torch tensors of shape [num_neurons].\n",
    "        \"\"\"\n",
    "        self.num_neurons = num_neurons\n",
    "        self.device = device\n",
    "        self.tau_m = tau_m.to(device)\n",
    "        self.v = torch.full((num_neurons,), v_rest, device=device)\n",
    "        self.v_rest = v_rest\n",
    "        self.v_thresh = v_thresh\n",
    "        self.v_reset = v_reset\n",
    "        self.refractory = refractory.to(device)\n",
    "        self.last_spike_time = torch.full((num_neurons,), -1e6, device=device)\n",
    "        self.spike_counts = torch.zeros((num_neurons,), device=device)\n",
    "\n",
    "    def update(self, t, dt, input_current):\n",
    "        not_refractory = (t - self.last_spike_time) >= self.refractory\n",
    "        dv = torch.zeros_like(self.v)\n",
    "        dv[not_refractory] = ((-self.v[not_refractory] + input_current[not_refractory]) * dt /\n",
    "                              self.tau_m[not_refractory])\n",
    "        self.v = self.v + dv\n",
    "        spiked = self.v >= self.v_thresh\n",
    "        if spiked.any():\n",
    "            self.last_spike_time[spiked] = t\n",
    "            self.v[spiked] = self.v_reset\n",
    "            self.spike_counts[spiked] += 1\n",
    "        return spiked.float()\n",
    "\n",
    "    def reset(self):\n",
    "        self.v.fill_(self.v_rest)\n",
    "        self.spike_counts.zero_()\n",
    "        self.last_spike_time.fill_(-1e6)\n",
    "\n",
    "# -------------------- GPU-Accelerated Actor-Critic Module --------------------\n",
    "class ActorCriticGPU:\n",
    "    def __init__(self, config, device):\n",
    "        self.config = config\n",
    "        num_critic = config[\"actor_critic\"][\"num_critic_neurons\"]\n",
    "        tau_m = torch.full((num_critic,), 20.0, device=device)\n",
    "        refractory = torch.full((num_critic,), 2.0, device=device)\n",
    "        self.critic_layer = LayerGPU(num_critic,\n",
    "                                     tau_m,\n",
    "                                     v_rest=config[\"neuron\"][\"v_rest\"],\n",
    "                                     v_thresh=config[\"neuron\"][\"v_thresh\"],\n",
    "                                     v_reset=config[\"neuron\"][\"v_reset\"],\n",
    "                                     refractory=refractory,\n",
    "                                     device=device)\n",
    "        self.last_value = 0.0\n",
    "\n",
    "    def compute_value(self):\n",
    "        return self.critic_layer.spike_counts.mean().item()\n",
    "\n",
    "    def update(self, reward, gamma):\n",
    "        current_value = self.compute_value()\n",
    "        delta = reward + gamma * current_value - self.last_value\n",
    "        self.last_value = current_value\n",
    "        return delta\n",
    "\n",
    "    def simulate(self, t, dt):\n",
    "        input_current = torch.zeros((self.critic_layer.num_neurons,), device=device)\n",
    "        self.critic_layer.update(t, dt, input_current)\n",
    "\n",
    "    def reset(self):\n",
    "        self.critic_layer.reset()\n",
    "        self.last_value = 0.0\n",
    "\n",
    "# -------------------- GPU-Accelerated PSAC Network --------------------\n",
    "class PSACNetworkGPU:\n",
    "    def __init__(self, config, device):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.dt = config[\"simulation\"][\"dt\"]\n",
    "        self.simulation_time = config[\"simulation\"][\"t_total\"]\n",
    "\n",
    "        self.retina = Retina(config=config)\n",
    "\n",
    "        # Initialize Middle (Liquid) Layer\n",
    "        num_middle = config[\"middle_layer\"][\"num_neurons\"]\n",
    "        num_exc = int(num_middle * config[\"middle_layer\"][\"ratio_exc\"])\n",
    "        tau_m = torch.empty(num_middle, device=device)\n",
    "        refractory = torch.empty(num_middle, device=device)\n",
    "        tau_m[:num_exc] = config[\"middle_layer\"][\"tau_m_exc\"]\n",
    "        refractory[:num_exc] = config[\"middle_layer\"][\"refractory_exc\"]\n",
    "        tau_m[num_exc:] = config[\"middle_layer\"][\"tau_m_inh\"]\n",
    "        refractory[num_exc:] = config[\"middle_layer\"][\"refractory_inh\"]\n",
    "        self.middle_layer = LayerGPU(num_middle,\n",
    "                                     tau_m,\n",
    "                                     v_rest=config[\"neuron\"][\"v_rest\"],\n",
    "                                     v_thresh=config[\"neuron\"][\"v_thresh\"],\n",
    "                                     v_reset=config[\"neuron\"][\"v_reset\"],\n",
    "                                     refractory=refractory,\n",
    "                                     device=device)\n",
    "\n",
    "        # Initialize Output Layer\n",
    "        num_output = config[\"output_layer\"][\"num_neurons\"]\n",
    "        tau_m_output = torch.full((num_output,), config[\"output_layer\"][\"tau_m\"], device=device)\n",
    "        refractory_output = torch.full((num_output,), config[\"output_layer\"][\"refractory\"], device=device)\n",
    "        self.output_layer = LayerGPU(num_output,\n",
    "                                     tau_m_output,\n",
    "                                     v_rest=config[\"neuron\"][\"v_rest\"],\n",
    "                                     v_thresh=config[\"neuron\"][\"v_thresh\"],\n",
    "                                     v_reset=config[\"neuron\"][\"v_reset\"],\n",
    "                                     refractory=refractory_output,\n",
    "                                     device=device)\n",
    "\n",
    "        # Initialize Actor-Critic Module\n",
    "        self.actor_critic = ActorCriticGPU(config, device)\n",
    "\n",
    "        # Connectivity from Middle to Output Layer\n",
    "        m = self.middle_layer.num_neurons\n",
    "        n = self.output_layer.num_neurons\n",
    "        self.middle_to_output = (torch.rand((m, n), device=device) < config[\"network\"][\"connection_prob\"]).float()\n",
    "        weights = torch.normal(0.5, 0.1, size=(m, n), device=device)\n",
    "        self.middle_to_output = self.middle_to_output * weights\n",
    "\n",
    "    def run_simulation(self, retina_spike_train, reward, verbose=False):\n",
    "        dt = self.dt\n",
    "        num_steps = retina_spike_train.shape[1]\n",
    "        output_spike_counts = torch.zeros((self.output_layer.num_neurons,), device=device)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            t = step * dt\n",
    "            retina_input = retina_spike_train[:, step].sum().item()\n",
    "            feed_forward = retina_input * 500.0  # scaling parameter (tunable)\n",
    "            middle_input = torch.full((self.middle_layer.num_neurons,), feed_forward, device=device)\n",
    "            middle_spikes = self.middle_layer.update(t, dt, middle_input)\n",
    "\n",
    "            output_input = torch.matmul(middle_spikes.unsqueeze(0), self.middle_to_output).squeeze(0)\n",
    "            output_input = output_input * 10.0  # tuning parameter (tunable)\n",
    "            output_spikes = self.output_layer.update(t, dt, output_input)\n",
    "\n",
    "            if t >= self.config[\"simulation\"][\"t_skip\"]:\n",
    "                output_spike_counts += output_spikes\n",
    "\n",
    "            self.actor_critic.simulate(t, dt)\n",
    "            if middle_spikes.sum() > 0 and output_spikes.sum() > 0:\n",
    "                delta = self.actor_critic.update(reward, self.config[\"actor_critic\"][\"gamma\"])\n",
    "                weight_update = self.config[\"learning\"][\"learning_rate\"] * delta\n",
    "                update_matrix = torch.ger(middle_spikes, output_spikes) * weight_update\n",
    "                self.middle_to_output += update_matrix\n",
    "                self.middle_to_output.clamp_(0, 1.0)\n",
    "\n",
    "            if verbose and step % 100 == 0:\n",
    "                print(f\"Time {t:.1f} ms: Middle spikes sum {middle_spikes.sum().item()}, Output spikes sum {output_spikes.sum().item()}\")\n",
    "\n",
    "        predicted_class = torch.argmax(output_spike_counts).item()\n",
    "        return predicted_class, output_spike_counts.cpu().numpy()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.middle_layer.reset()\n",
    "        self.output_layer.reset()\n",
    "        self.actor_critic.reset()\n",
    "\n",
    "# -------------------- Helper: Reward Function --------------------\n",
    "def compute_reward(predicted_class, true_label):\n",
    "    return 1.0 if predicted_class == true_label else -1.0\n",
    "\n",
    "# -------------------- Training Loop --------------------\n",
    "def train_network():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.squeeze(0) * 255)\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"training\"][\"batch_size\"], shuffle=True)\n",
    "\n",
    "    retina = Retina(CONFIG)\n",
    "    network = PSACNetworkGPU(CONFIG, device)\n",
    "\n",
    "    num_epochs = CONFIG[\"training\"][\"num_epochs\"]\n",
    "    total_samples = 0\n",
    "    correct_samples = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
    "        for batch_idx, (image, label) in enumerate(train_loader):\n",
    "            try:\n",
    "                image_np = image.squeeze(0).numpy().astype(np.uint8)\n",
    "                true_label = label.item()\n",
    "                spike_rates = retina.process_image(image_np)\n",
    "                retina_spike_train = retina.generate_spike_train(spike_rates, CONFIG[\"simulation\"][\"t_total\"], CONFIG[\"simulation\"][\"dt\"])\n",
    "                network.reset_state()\n",
    "                predicted_class, _ = network.run_simulation(retina_spike_train, reward=0.0, verbose=(batch_idx < 2))\n",
    "                reward = compute_reward(predicted_class, true_label)\n",
    "                network.reset_state()\n",
    "                predicted_class, _ = network.run_simulation(retina_spike_train, reward=reward, verbose=False)\n",
    "                total_samples += 1\n",
    "                if predicted_class == true_label:\n",
    "                    correct_samples += 1\n",
    "                if (batch_idx + 1) % 100 == 0:\n",
    "                    print(f\"Sample {batch_idx+1}: True {true_label}, Predicted {predicted_class}, Running accuracy = {correct_samples/total_samples:.2f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample index {batch_idx}. True label: {label.item()}.\")\n",
    "                raise e\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy: {correct_samples/total_samples:.2f}\")\n",
    "    print(f\"Final Training Accuracy: {correct_samples/total_samples:.2f}\")\n",
    "    return network\n",
    "\n",
    "# -------------------- Testing Loop --------------------\n",
    "def test_network():\n",
    "    network = PSACNetworkGPU(CONFIG, device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.squeeze(0) * 255)\n",
    "    ])\n",
    "    test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    retina = Retina(CONFIG)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    print(f\"Starting testing on {len(test_dataset)} samples.\")\n",
    "    for idx, (image, label) in enumerate(test_loader):\n",
    "        try:\n",
    "            image_np = image.squeeze(0).numpy().astype(np.uint8)\n",
    "            true_label = label.item()\n",
    "            spike_rates = retina.process_image(image_np)\n",
    "            retina_spike_train = retina.generate_spike_train(spike_rates, CONFIG[\"simulation\"][\"t_total\"], CONFIG[\"simulation\"][\"dt\"])\n",
    "            network.reset_state()\n",
    "            predicted_class, _ = network.run_simulation(retina_spike_train, reward=0.0, verbose=False)\n",
    "            total += 1\n",
    "            if predicted_class == true_label:\n",
    "                correct += 1\n",
    "            if total % 100 == 0:\n",
    "                print(f\"[{total}/{len(test_dataset)}] Processed sample {total}: True label = {true_label}, Predicted = {predicted_class}, Running accuracy = {correct/total:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample index {idx}.\")\n",
    "            raise e\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "    print(f\"Final Test Accuracy: {acc:.2f}\")\n",
    "\n",
    "# -------------------- Run Training and Testing --------------------\n",
    "# In a notebook, you can run these cells interactively.\n",
    "trained_network = train_network()\n",
    "test_network(trained_network)\n",
    "\n",
    "# Optionally, visualize the output spike counts for one sample from the test set.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.squeeze(0) * 255)\n",
    "])\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "sample, label = test_dataset[0]\n",
    "sample_np = sample.numpy().astype(np.uint8)\n",
    "print(\"Visualizing output for test sample, True label:\", label)\n",
    "retina = Retina(CONFIG)\n",
    "spike_rates = retina.process_image(sample_np)\n",
    "retina_spike_train = retina.generate_spike_train(spike_rates, CONFIG[\"simulation\"][\"t_total\"], CONFIG[\"simulation\"][\"dt\"])\n",
    "trained_network.reset_state()\n",
    "predicted_class, output_counts = trained_network.run_simulation(retina_spike_train, reward=0.0, verbose=False)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(len(output_counts)), output_counts)\n",
    "plt.xlabel(\"Output Neuron (Class)\")\n",
    "plt.ylabel(\"Spike Count\")\n",
    "plt.title(\"Output Layer Spike Counts\")\n",
    "plt.show()\n"
   ],
   "id": "7cd116039af94a55"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
